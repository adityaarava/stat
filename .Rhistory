colnames(obesity)
set.seed(123)
train_indices <- sample(nrow(obesity), nrow(obesity) * 0.8)
train_data <- obesity[train_indices, ]
test_data <- obesity[-train_indices, ]
model <- rpart(family_history_with_overweight ~ ., data = train_data)
rpart.plot(model)
obesity$family_history_with_overweight <- as.factor(obesity$family_history_with_overweight)
obesity$Obesity_Levels <- as.factor(obesity$Obesity_Levels)
# Create a contingency table
contingency_table <- table(obesity$family_history_with_overweight, obesity$Obesity_Levels)
# Perform chi-square test
chi_sq_test <- chisq.test(contingency_table)
# Print the results
print(chi_sq_test)
library(dplyr)
obesity_distribution <- obesity %>%
group_by(family_history_with_overweight, Obesity_Levels) %>%
summarise(count = dplyr::n(), .groups = 'drop')
# View the table to ensure correctness
print(obesity_distribution)
library(plotly)
# Plotting with Plotly Express
plot_ly(data = obesity_distribution, x = ~Obesity_Levels, y = ~count, color = ~family_history_with_overweight,
type = "bar", barmode = "group") %>%
layout(title = "Distribution of Obesity Levels by Family History of Overweight",
xaxis = list(title = "Obesity Levels"),
yaxis = list(title = "Count"),
legend = list(title = "Family History: Overweight")) %>%
layout(legend = list(orientation = "h", x = 0.5, y = -0.15)) %>%
layout(font = list(size = 11, family = "Arial")) # Adjust font size and family
# Convert categorical variables to factors
obesity$family_history_with_overweight <- factor(obesity$family_history_with_overweight, levels = c("yes", "no"))
obesity$Smoking_Habit <- factor(obesity$Smoking_Habit, levels = c("yes", "no"))
obesity$Technology_dependency <- factor(obesity$Technology_dependency, levels = c("yes", "no"))
obesity$Mode_of_Transportation <- factor(obesity$Mode_of_Transportation)
obesity$Obesity_Levels <- factor(obesity$Obesity_Levels)
str(obesity)
# Fit logistic regression model
logit_model <- glm(Obesity_Levels ~ family_history_with_overweight, data = obesity, family = binomial)
# Summary of the model
summary(logit_model)
set.seed(123)
train_indices <- sample(nrow(obesity), nrow(obesity) * 0.8)
train_data <- obesity[train_indices, ]
test_data <- obesity[-train_indices, ]
model <- rpart(family_history_with_overweight ~ ., data = train_data)
# Visualize the tree
rpart.plot(model)
library(ggplot2)
library(car)
library(caret)
library(MASS)
library(dplyr)
obesity <- na.omit(obesity)
obesity$Highcaloric_food <- as.numeric(obesity$Highcaloric_food == "yes")
obesity$Smoking_Habit <- as.numeric(obesity$Smoking_Habit == "yes")
lm_model <- lm(Weight ~ Highcaloric_food + Vegetable_intake + Smoking_Habit + Technology_dependency, obesity = obesity)
gc()
library(caret)
library(MASS)
library(leaps)
library(ggplot2)
library(GGally)
library(psych)
library(car)
library(tidyr)
library(gridExtra)
library(rpart)
library(tree)
library(rpart.plot)
library(caret)
library(plotly)
library(vcd)
obesity=read.csv("C:\\Users\\arava\\OneDrive\\Desktop\\STAT515\\modified_obesity_data.csv")
colnames(obesity)
set.seed(123)
train_indices <- sample(nrow(obesity), nrow(obesity) * 0.8)
train_data <- obesity[train_indices, ]
test_data <- obesity[-train_indices, ]
model <- rpart(family_history_with_overweight ~ ., data = train_data)
rpart.plot(model)
obesity$family_history_with_overweight <- as.factor(obesity$family_history_with_overweight)
obesity$Obesity_Levels <- as.factor(obesity$Obesity_Levels)
# Create a contingency table
contingency_table <- table(obesity$family_history_with_overweight, obesity$Obesity_Levels)
# Perform chi-square test
chi_sq_test <- chisq.test(contingency_table)
# Print the results
print(chi_sq_test)
library(dplyr)
obesity_distribution <- obesity %>%
group_by(family_history_with_overweight, Obesity_Levels) %>%
summarise(count = dplyr::n(), .groups = 'drop')
# View the table to ensure correctness
print(obesity_distribution)
library(plotly)
# Plotting with Plotly Express
plot_ly(data = obesity_distribution, x = ~Obesity_Levels, y = ~count, color = ~family_history_with_overweight,
type = "bar", barmode = "group") %>%
layout(title = "Distribution of Obesity Levels by Family History of Overweight",
xaxis = list(title = "Obesity Levels"),
yaxis = list(title = "Count"),
legend = list(title = "Family History: Overweight")) %>%
layout(legend = list(orientation = "h", x = 0.5, y = -0.15)) %>%
layout(font = list(size = 11, family = "Arial")) # Adjust font size and family
library(ggplot2)
library(car)
library(caret)
library(MASS)
library(dplyr)
data <- read.csv("C:\\Users\\arava\\OneDrive\\Desktop\\STAT515\\modified_obesity_data.csv")
data <- na.omit(data)
data$Highcaloric_food <- as.numeric(data$Highcaloric_food == "yes")
data$Smoking_Habit <- as.numeric(data$Smoking_Habit == "yes")
lm_model <- lm(Weight ~ Highcaloric_food + Vegetable_intake + Smoking_Habit + Technology_dependency, data = data)
stepwise_adj_r2 <- function(model, data) {
current_adj_r2 <- summary(model)$adj.r.squared
predictors <- names(coef(model))
best_model <- model
improvement <- TRUE
while (improvement) {
improvement <- FALSE
best_adj_r2 <- current_adj_r2
for (predictor in predictors[-1]) {
formula <- as.formula(paste("Weight ~", paste(setdiff(predictors[-1], predictor), collapse = " + ")))
candidate_model <- lm(formula, data = data)
candidate_adj_r2 <- summary(candidate_model)$adj.r.squared
if (candidate_adj_r2 > best_adj_r2) {
best_adj_r2 <- candidate_adj_r2
best_model <- candidate_model
improvement <- TRUE
}
}
if (improvement) {
current_adj_r2 <- best_adj_r2
predictors <- names(coef(best_model))
}
}
return(best_model)
}
final_model <- stepwise_adj_r2(lm_model, data)
summary_final_model <- summary(final_model)
print(summary_final_model)
# Coefficient plot
coef_plot_adj_r2 <- ggplot(data = as.data.frame(coef(summary(final_model))), aes(x = rownames(coef(summary(final_model))), y = Estimate)) +
geom_bar(stat = "identity", fill = "orange", color = "black") +
labs(title = "Coefficients of Predictors (Adjusted R-Squared Criterion)", x = "Predictors", y = "Coefficient Estimate") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(coef_plot_adj_r2)
# Residual plot
residual_plot_adj_r2 <- ggplot(data, aes(x = fitted(final_model), y = residuals(final_model))) +
geom_point(color = "green") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot (Adjusted R-Squared Criterion)", x = "Fitted Values", y = "Residuals") +
theme_minimal()
print(residual_plot_adj_r2)
# Residual plot
residual_plot_adj_r2 <- ggplot(data, aes(x = fitted(final_model), y = residuals(final_model))) +
geom_point(color = "blue") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot (Adjusted R-Squared Criterion)", x = "Fitted Values", y = "Residuals") +
theme_minimal()
print(residual_plot_adj_r2)
# Residual plot
residual_plot_adj_r2 <- ggplot(data, aes(x = fitted(final_model), y = residuals(final_model))) +
geom_point(color = "black") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot (Adjusted R-Squared Criterion)", x = "Fitted Values", y = "Residuals") +
theme_minimal()
print(residual_plot_adj_r2)
# Variable importance plot
var_importance_adj_r2 <- ggplot(data = as.data.frame(varImp(final_model)), aes(x = rownames(varImp(final_model)), y = Overall)) +
geom_bar(stat = "identity", fill = "cornsilk", color = "black") +
labs(title = "Variable Importance", x = "Predictors", y = "Importance") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(var_importance_adj_r2)
# Coefficient plot
coef_plot_adj_r2 <- ggplot(data = as.data.frame(coef(summary(final_model))), aes(x = rownames(coef(summary(final_model))), y = Estimate)) +
geom_bar(stat = "identity", fill = "orange", color = "black") +
labs(title = "Coefficients of Predictors (Adjusted R-Squared Criterion)", x = "Predictors", y = "Coefficient Estimate") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(coef_plot_adj_r2)
# Residual plot
residual_plot_adj_r2 <- ggplot(data, aes(x = fitted(final_model), y = residuals(final_model))) +
geom_point(color = "black") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot (Adjusted R-Squared Criterion)", x = "Fitted Values", y = "Residuals") +
theme_minimal()
print(residual_plot_adj_r2)
# Variable importance plot
var_importance_adj_r2 <- ggplot(data = as.data.frame(varImp(final_model)), aes(x = rownames(varImp(final_model)), y = Overall)) +
geom_bar(stat = "identity", fill = "cornsilk", color = "black") +
labs(title = "Variable Importance", x = "Predictors", y = "Importance") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(var_importance_adj_r2)
install.packages("corrplot")
# Load necessary libraries
library(ggplot2)
library(corrplot)
# Read the data
health_data <- read.csv("C:\\Users\\arava\\OneDrive\\Desktop\\STAT515\\modified_obesity_data.csv")
# Load necessary libraries
library(ggplot2)
library(corrplot)
# Read the data
health_data <- read.csv("C:\\Users\\arava\\OneDrive\\Desktop\\STAT515\\modified_obesity_data.csv")
# Convert columns to appropriate data types if needed
health_data$Age <- as.numeric(as.character(health_data$Age))
health_data$Height <- as.numeric(as.character(health_data$Height))
health_data$Weight <- as.numeric(as.character(health_data$Weight))
# Convert other columns to appropriate data types as needed...
# Summary statistics
summary(health_data)
# Histograms
par(mfrow=c(3, 3))
for (i in 2:ncol(health_data)) {
if (is.numeric(health_data[, i])) {
hist(health_data[,i], main=names(health_data)[i], xlab="")
}
}
# Box plots
par(mfrow=c(3, 3))
for (i in 2:ncol(health_data)) {
if (is.numeric(health_data[, i])) {
boxplot(health_data[,i] ~ health_data$Obesity_Levels, main=names(health_data)[i], xlab="Obesity Levels", ylab=names(health_data)[i])
}
}
# Scatter plot matrix
# Filter numeric columns
numeric_cols <- sapply(health_data, is.numeric)
numeric_data <- health_data[, numeric_cols]
# Scatter plot matrix
pairs(numeric_data, pch = 16)
health_data <- read.csv("C:\\Users\\arava\\OneDrive\\Desktop\\STAT515\\modified_obesity_data.csv")
# Select relevant features
selected_features <- health_data[, c("Age", "Height", "Weight", "family_history_with_overweight", "Highcaloric_food",
"Vegetable_intake", "Main_Meal_Intake", "Food_between_meals", "Smoking_Habit",
"Water_intake", "Calorie_Intake", "PHYSICAL_Activity", "Technology_dependency",
"Alcohol_Consumption", "Mode_of_Transportation")]
# Check for missing values and handle if necessary
# For example: selected_features <- na.omit(selected_features)
# Perform feature scaling or normalization
# Here, we'll use z-score standardization
# Exclude non-numeric columns before scaling
numeric_features <- selected_features[, sapply(selected_features, is.numeric)]
# Perform feature scaling
scaled_features <- scale(numeric_features)
# Print the scaled features
print(scaled_features)
# Print the scaled features
print(scaled_features)
library(cluster)
library(factoextra)
# Read the data
health_data <- read.csv("C:\\Users\\arava\\OneDrive\\Desktop\\STAT515\\modified_obesity_data.csv")
# Select relevant features for clustering
selected_features <- health_data[, c("Age", "Height", "Weight", "family_history_with_overweight", "Highcaloric_food",
"Vegetable_intake", "Main_Meal_Intake", "Food_between_meals", "Smoking_Habit",
"Water_intake", "Calorie_Intake", "PHYSICAL_Activity", "Technology_dependency",
"Alcohol_Consumption", "Mode_of_Transportation")]
# Convert categorical variables to factors if needed
# Convert categorical variables to dummy variables
selected_features <- model.matrix(~ . - 1, data = selected_features)
# Perform K-means clustering
kmeans_result <- kmeans(selected_features, centers = k)
library(cluster)
library(factoextra)
# Read the data
health_data <- read.csv("C:\\Users\\arava\\OneDrive\\Desktop\\STAT515\\modified_obesity_data.csv")
# Select relevant features for clustering
selected_features <- health_data[, c("Age", "Height", "Weight", "family_history_with_overweight", "Highcaloric_food",
"Vegetable_intake", "Main_Meal_Intake", "Food_between_meals", "Smoking_Habit",
"Water_intake", "Calorie_Intake", "PHYSICAL_Activity", "Technology_dependency",
"Alcohol_Consumption", "Mode_of_Transportation")]
# Convert categorical variables to factors if needed
# Convert categorical variables to dummy variables
selected_features <- model.matrix(~ . - 1, data = selected_features)
# Perform K-means clustering
k=3
kmeans_result <- kmeans(selected_features, centers = k)
# Handle missing values if any
# Example: selected_features <- na.omit(selected_features)
# Perform K-means clustering
k <- 3  # Number of clusters
set.seed(123)  # Set seed for reproducibility
kmeans_result <- kmeans(selected_features, centers = k)
# Adjust plot parameters for better visibility
fviz_cluster(kmeans_result,
geom = "point",
data = selected_features,
stand = FALSE,  # Disable scaling for better visibility
ellipse.type = "convex",  # Use convex hulls for clusters
ellipse.level = 0.95,  # Confidence level for ellipses
palette = "jco",  # Color palette
ggtheme = theme_minimal() +  # Combine themes
theme(legend.position = "bottom"),  # Adjust legend position
main = paste("K-means Clustering (K =", k, ")"),  # Main title
show.clust.cent = TRUE,  # Show cluster centers
pointsize = 2)  # Adjust point size for better visibility
# Evaluate clusters
silhouette_score <- silhouette(kmeans_result$cluster, dist(selected_features))
silhouette_score
library(cluster)
library(factoextra)
# Read the data
health_data <- read.csv("C:\\Users\\arava\\OneDrive\\Desktop\\STAT515\\modified_obesity_data.csv")
# Select relevant features for clustering
selected_features <- health_data[, c("Age", "Height", "Weight", "family_history_with_overweight", "Highcaloric_food",
"Vegetable_intake", "Main_Meal_Intake", "Food_between_meals", "Smoking_Habit",
"Water_intake", "Calorie_Intake", "PHYSICAL_Activity", "Technology_dependency",
"Alcohol_Consumption", "Mode_of_Transportation")]
# Convert categorical variables to factors if needed
# Convert categorical variables to dummy variables
selected_features <- model.matrix(~ . - 1, data = selected_features)
# Perform K-means clustering
k=3
kmeans_result <- kmeans(selected_features, centers = k)
# Handle missing values if any
# Example: selected_features <- na.omit(selected_features)
# Perform K-means clustering
k <- 3  # Number of clusters
set.seed(123)  # Set seed for reproducibility
kmeans_result <- kmeans(selected_features, centers = k)
# Adjust plot parameters for better visibility
fviz_cluster(kmeans_result,
geom = "point",
data = selected_features,
stand = FALSE,  # Disable scaling for better visibility
ellipse.type = "convex",  # Use convex hulls for clusters
ellipse.level = 0.95,  # Confidence level for ellipses
palette = "jco",  # Color palette
ggtheme = theme_minimal() +  # Combine themes
theme(legend.position = "bottom"),  # Adjust legend position
main = paste("K-means Clustering (K =", k, ")"),  # Main title
show.clust.cent = TRUE,  # Show cluster centers
pointsize = 2)  # Adjust point size for better visibility
# Evaluate clusters
silhouette_score <- silhouette(kmeans_result$cluster, dist(selected_features))
library(cluster)
library(factoextra)
# Read the data
health_data <- read.csv("C:\\Users\\arava\\OneDrive\\Desktop\\STAT515\\modified_obesity_data.csv")
# Select relevant features for clustering
selected_features <- health_data[, c("Age", "Height", "Weight", "family_history_with_overweight", "Highcaloric_food",
"Vegetable_intake", "Main_Meal_Intake", "Food_between_meals", "Smoking_Habit",
"Water_intake", "Calorie_Intake", "PHYSICAL_Activity", "Technology_dependency",
"Alcohol_Consumption", "Mode_of_Transportation")]
# Convert categorical variables to factors if needed
# Convert categorical variables to dummy variables
selected_features <- model.matrix(~ . - 1, data = selected_features)
# Perform K-means clustering
k=3
kmeans_result <- kmeans(selected_features, centers = k)
# Handle missing values if any
# Example: selected_features <- na.omit(selected_features)
# Perform K-means clustering
k <- 3  # Number of clusters
set.seed(123)  # Set seed for reproducibility
kmeans_result <- kmeans(selected_features, centers = k)
# Adjust plot parameters for better visibility
fviz_cluster(kmeans_result,
geom = "point",
data = selected_features,
stand = FALSE,  # Disable scaling for better visibility
ellipse.type = "convex",  # Use convex hulls for clusters
ellipse.level = 0.95,  # Confidence level for ellipses
palette = "jco",  # Color palette
ggtheme = theme_minimal() +  # Combine themes
theme(legend.position = "bottom"),  # Adjust legend position
main = paste("K-means Clustering (K =", k, ")"),  # Main title
show.clust.cent = TRUE,  # Show cluster centers
pointsize = 2)  # Adjust point size for better visibility
# Evaluate clusters
silhouette_score <- silhouette(kmeans_result$cluster, dist(selected_features))
silhouette_score
library(cluster)
library(factoextra)
# Read the data
health_data <- read.csv("C:\\Users\\arava\\OneDrive\\Desktop\\STAT515\\modified_obesity_data.csv")
# Select relevant features for clustering
selected_features <- health_data[, c("Age", "Height", "Weight", "family_history_with_overweight", "Highcaloric_food",
"Vegetable_intake", "Main_Meal_Intake", "Food_between_meals", "Smoking_Habit",
"Water_intake", "Calorie_Intake", "PHYSICAL_Activity", "Technology_dependency",
"Alcohol_Consumption", "Mode_of_Transportation")]
# Convert categorical variables to factors if needed
# Convert categorical variables to dummy variables
selected_features <- model.matrix(~ . - 1, data = selected_features)
# Perform K-means clustering
k=3
kmeans_result <- kmeans(selected_features, centers = k)
# Handle missing values if any
# Example: selected_features <- na.omit(selected_features)
# Perform K-means clustering
k <- 3  # Number of clusters
set.seed(123)  # Set seed for reproducibility
kmeans_result <- kmeans(selected_features, centers = k)
# Adjust plot parameters for better visibility
fviz_cluster(kmeans_result,
geom = "point",
data = selected_features,
stand = FALSE,  # Disable scaling for better visibility
ellipse.type = "convex",  # Use convex hulls for clusters
ellipse.level = 0.95,  # Confidence level for ellipses
palette = "jco",  # Color palette
ggtheme = theme_minimal() +  # Combine themes
theme(legend.position = "bottom"),  # Adjust legend position
main = paste("K-means Clustering (K =", k, ")"),  # Main title
show.clust.cent = TRUE,  # Show cluster centers
pointsize = 2)  # Adjust point size for better visibility
# Evaluate clusters
silhouette_score <- silhouette(kmeans_result$cluster, dist(selected_features))
```{r}
#| code-fold: true
#| code-summary: "Show the code"
# Coefficient plot
coef_plot_adj_r2 <- ggplot(data = as.data.frame(coef(summary(final_model))), aes(x = rownames(coef(summary(final_model))), y = Estimate)) +
geom_bar(stat = "identity", fill = "orange", color = "black") +
labs(title = "Coefficients of Predictors (Adjusted R-Squared Criterion)", x = "Predictors", y = "Coefficient Estimate") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(coef_plot_adj_r2)
#| code-fold: true
#| code-summary: "Show the code"
library(ggplot2)
library(car)
library(caret)
library(MASS)
library(dplyr)
data <- read.csv("C:\\Users\\arava\\OneDrive\\Desktop\\STAT515\\modified_obesity_data.csv")
#| code-fold: true
#| code-summary: "Show the code"
data <- na.omit(data)
data$Highcaloric_food <- as.numeric(data$Highcaloric_food == "yes")
data$Smoking_Habit <- as.numeric(data$Smoking_Habit == "yes")
#| code-fold: true
#| code-summary: "Show the code"
lm_model <- lm(Weight ~ Highcaloric_food + Vegetable_intake + Smoking_Habit + Technology_dependency, data = data)
#| code-fold: true
#| code-summary: "Show the code"
stepwise_adj_r2 <- function(model, data) {
current_adj_r2 <- summary(model)$adj.r.squared
predictors <- names(coef(model))
best_model <- model
improvement <- TRUE
while (improvement) {
improvement <- FALSE
best_adj_r2 <- current_adj_r2
for (predictor in predictors[-1]) {
formula <- as.formula(paste("Weight ~", paste(setdiff(predictors[-1], predictor), collapse = " + ")))
candidate_model <- lm(formula, data = data)
candidate_adj_r2 <- summary(candidate_model)$adj.r.squared
if (candidate_adj_r2 > best_adj_r2) {
best_adj_r2 <- candidate_adj_r2
best_model <- candidate_model
improvement <- TRUE
}
}
if (improvement) {
current_adj_r2 <- best_adj_r2
predictors <- names(coef(best_model))
}
}
return(best_model)
}
#| code-fold: true
#| code-summary: "Show the code"
final_model <- stepwise_adj_r2(lm_model, data)
#| code-fold: true
#| code-summary: "Show the code"
summary_final_model <- summary(final_model)
print(summary_final_model)
#| code-fold: true
#| code-summary: "Show the code"
# Coefficient plot
coef_plot_adj_r2 <- ggplot(data = as.data.frame(coef(summary(final_model))), aes(x = rownames(coef(summary(final_model))), y = Estimate)) +
geom_bar(stat = "identity", fill = "orange", color = "black") +
labs(title = "Coefficients of Predictors (Adjusted R-Squared Criterion)", x = "Predictors", y = "Coefficient Estimate") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(coef_plot_adj_r2)
#| code-fold: true
#| code-summary: "Show the code"
# Residual plot
residual_plot_adj_r2 <- ggplot(data, aes(x = fitted(final_model), y = residuals(final_model))) +
geom_point(color = "black") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot (Adjusted R-Squared Criterion)", x = "Fitted Values", y = "Residuals") +
theme_minimal()
print(residual_plot_adj_r2)
#| code-fold: true
#| code-summary: "Show the code"
# Variable importance plot
var_importance_adj_r2 <- ggplot(data = as.data.frame(varImp(final_model)), aes(x = rownames(varImp(final_model)), y = Overall)) +
geom_bar(stat = "identity", fill = "cornsilk", color = "black") +
labs(title = "Variable Importance", x = "Predictors", y = "Importance") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(var_importance_adj_r2)
#| code-fold: true
#| code-summary: "Show the code"
# Residual plot
residual_plot_adj_r2 <- ggplot(data, aes(x = fitted(final_model), y = residuals(final_model))) +
geom_point(color = "black") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot (Adjusted R-Squared Criterion)", x = "Fitted Values", y = "Residuals") +
theme_minimal()
print(residual_plot_adj_r2)
