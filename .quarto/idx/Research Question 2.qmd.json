{"title":"Research Question 2","markdown":{"yaml":{"title":"Research Question 2"},"headingText":"Coefficient plot","containsRefs":false,"markdown":"\n\n**Research Question 2:**\n\nHow do factors like high-caloric food intake, smoking habits, vegetable intake and technology dependency correlate with weight?\n\n**Methodology:**\n\nThe above research question can be solved by using multilinear regression and variable selection.Adjusted R-square values is used as a criterion to perform the variable selection.\n\n**The statistical analysis of this dataset involves several steps:**\n\n-   **Data Loading:**\n\nFirstly,we need to load the CSV file.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\nlibrary(ggplot2)\nlibrary(car)\nlibrary(caret)\nlibrary(MASS)\nlibrary(dplyr)\n\ndata <- read.csv(\"C:\\\\Users\\\\arava\\\\OneDrive\\\\Desktop\\\\STAT515\\\\modified_obesity_data.csv\")\n```\n\n-   **Data Preprocessing:**\n\nThis step involves data cleaning where rows with missing values are deleted and categorical variables are converted into dummy numerical variables.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\n\ndata <- na.omit(data)\ndata$Highcaloric_food <- as.numeric(data$Highcaloric_food == \"yes\")\ndata$Smoking_Habit <- as.numeric(data$Smoking_Habit == \"yes\")\n```\n\n-   **Model Building:**\n\nWe build a linear model with Highcaloric_food, Smoking_Habit, Vegetable_intake and Technology_dependency as predictors and Weight as the dependent variable.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\nlm_model <- lm(Weight ~ Highcaloric_food + Vegetable_intake + Smoking_Habit + Technology_dependency, data = data)\n\n```\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\nstepwise_adj_r2 <- function(model, data) {\n  current_adj_r2 <- summary(model)$adj.r.squared\n  predictors <- names(coef(model))\n  best_model <- model\n  improvement <- TRUE\n  \n  while (improvement) {\n    improvement <- FALSE\n    best_adj_r2 <- current_adj_r2\n    \n    for (predictor in predictors[-1]) { \n      formula <- as.formula(paste(\"Weight ~\", paste(setdiff(predictors[-1], predictor), collapse = \" + \")))\n      candidate_model <- lm(formula, data = data)\n      candidate_adj_r2 <- summary(candidate_model)$adj.r.squared\n      \n      if (candidate_adj_r2 > best_adj_r2) {\n        best_adj_r2 <- candidate_adj_r2\n        best_model <- candidate_model\n        improvement <- TRUE\n      }\n    }\n    \n    if (improvement) {\n      current_adj_r2 <- best_adj_r2\n      predictors <- names(coef(best_model))\n    }\n  }\n  \n  return(best_model)\n}\n```\n\n-   **Variable Selection:**\n\nAfter building  a model the next step is to perform Stepwise regression which is a variable selection technique by taking Adjusted R-squared values as a criterion to improve the model fitting.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\nfinal_model <- stepwise_adj_r2(lm_model, data)\n```\n\n-   **Displaying the Outputs and Plots:**\n\n After performing stepwise selection the summary of the final model is printed which gives the coefficients, significance levels, and statistics like R-squared values and F-statistics.We also print the coefficient plot, residual plot and variable Importance plot.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\nsummary_final_model <- summary(final_model)\nprint(summary_final_model)\n```\n\n**Summary of the model:**\n\n-   **Residuals:**\n\nResiduals are the differences between the observed values of the dependent variable (Weight) and the values predicted by the model.\n\n**Min**\n\nThe model underpredicted this observation by 55.505 units, given the smallest residual as -55.505.\n\n**First Quartile**\n\nFor a quarter of the data, the model's predictions are around 17.647 units too high, as indicated by 25% of the residuals being smaller than -17.647.\n\n**Median**\n\nThe median residual is very close to 0 (0.165), indicating that the model's predictions are generally accurate, as half of the residuals are below this value and half are above.\n\n**Third Quartile**\n\nMost observations have the model's prediction within about 15.725 units of the actual values, as indicated by the 75% of residuals being smaller than 15.725**.**\n\n**Max**\n\nThe greatest residual, which is 78.498 units, indicates that the highest underprediction of the model for any given observation is 78.498 units.\n\n-   **Coefficients:**\n\nThe predictors' coefficients indicate the expected rise in the dependent variable (weight) for each unit increase in the predictor, assuming no change in the other predictors.\n\n**Intercept**\n\nThe expected weight is about 42.33 units when all predictors are zero.\n\n**Highcaloric_food**\n\nIn comparison to not consuming high-calorie food, there is an average weight rise of 23.19 units linked to high-calorie food consumption\n\n**Vegetable_intake**\n\nWeight increases by around 10.66 units for every unit increase in vegetable intake.\n\n**Smoking_Habit**\n\nThe average weight rise of smokers  is 8.35 units higher than that of non-smokers.\n\n**Technology_dependency**\n\nWeight drops by 3.00 units for every unit increase in technological dependency.\n\n-   **Statistical Significance(Pr(\\>\\|t\\|)):**\n\n    It provides the p values to determine whether the model is statistically significant or not.Significance level(alpha) is generally set to 0.05. The null hypothesis states that no effect or no difference between groups whereas the alternative hypothesis stating that there is a  difference between groups.If the p\\< alpha(0.05)  the model is considered statistically significant, and the null hypothesis is rejected in favor of the alternative hypothesis.From the summary we can see that p values of all the predictors \\< 0.05 therefore suggesting that the model is statistically significant.\n\n-   **Residual Standard Error:**\n\n    This indicates how much the expected values differ from the actual values on an average.The deviation of the model is around 24.54 weight units.\n\n-   **Multiple R-squared (0.1283) and Adjusted R-squared (0.1266):**\n\n    The model accounts for approximately 12.83% of the variance observed in the dependent variable, weight.When several predictors are present, the adjusted measure becomes more accurate since it accounts for approximately 12.66% of the variation in the model.\n\n-   **F-statistic and its p-value:**\n\n```         \nThis tests whether at least one predictor variable has a non-zero coefficient or not. The less p values states that the model is statistically significant.\n```\n\nIn conclusion we can say that the model is statistically significant but with an Adjusted R-squared value of 0.1266 we can say that there is a small variance in the weight.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\ncoef_plot_adj_r2 <- ggplot(data = as.data.frame(coef(summary(final_model))), aes(x = rownames(coef(summary(final_model))), y = Estimate)) +\n  geom_bar(stat = \"identity\", fill = \"orange\", color = \"black\") +\n  labs(title = \"Coefficients of Predictors (Adjusted R-Squared Criterion)\", x = \"Predictors\", y = \"Coefficient Estimate\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\nprint(coef_plot_adj_r2)\n```\n\nThe above bar chart displays the coefficient estimates for each predictor in the regression model.\n\n**Implications of the Coefficients:**\n\n**Positive coefficients**(Highcaloric_food, Vegetable_intake, Smoking_Habit) shows a direct relationship with weight, where increases in these variables are associated with increases in weight.\n\n**Negative coefficient** (Technology_dependency) shows an inverse relationship, where increases in this variable are associated with decreases in weight.\n\n**Conclusion:**\n\nThe strength and influence of each predictor on the dependent variable weight, are shown by the relative sizes of the bars. Highcaloric_food shows the most dominant effect, followed by vegetable_intake suggesting that these variables are the most important contributors to the difference in weight shown in your data. The figure clearly illustrates the various effects of dietary and lifestyle choices on weight and offers a visual representation of the regression results that were previously presented.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\n# Residual plot\nresidual_plot_adj_r2 <- ggplot(data, aes(x = fitted(final_model), y = residuals(final_model))) +\n  geom_point(color = \"black\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Residual Plot (Adjusted R-Squared Criterion)\", x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()\nprint(residual_plot_adj_r2)\n```\n\nThe residual shows the residuals on the vertical axis (the differences between observed and predicted values) plotted against the fitted values(predicted) on the horizontal axis.The dashed red line at zero indicates perfect prediction by the model.The residual plot shows residuals scattered randomly around zero, mostly on the positive side. However, distinct clusters around certain predictions, such as 80 and 100, suggest possible missing nonlinear effects or interactions in the model.Extreme outliers, both above and below the zero line, require investigation for potential data errors.Clear patterns, such as vertical clustering, indicate potential issues like incorrect assumptions about variable relationships or overrepresentation of predictor levels in certain ranges.\n\nIn conclusion,the residual plot is a tool for diagnostic checking. It helps in assessing whether the assumptions of linear regression (linearity, independence, constant varience, and normality of residuals) are reasonably satisfied or if further model improvements are needed or not.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\n# Variable importance plot\nvar_importance_adj_r2 <- ggplot(data = as.data.frame(varImp(final_model)), aes(x = rownames(varImp(final_model)), y = Overall)) +\n  geom_bar(stat = \"identity\", fill = \"cornsilk\", color = \"black\") +\n  labs(title = \"Variable Importance\", x = \"Predictors\", y = \"Importance\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\nprint(var_importance_adj_r2)\n```\n\nThe Variable Importance bar chart visually represents the relative importance of different predictors in the regression model. Highcaloric_food predictor has the highest importance in the model, indicating that it has a potential effect on the dependent variable (weight). This aligns with the earlier regression output where the coefficient for high-caloric food intake was significantly positive, suggesting a strong association with increased weight. Smoking_habit shows the least importance compared to all the predictors. This lesser importance reflects its relatively lower coefficient and it was also marginally significant in the regression analysis (p-value close to the typical significance threshold of 0.05).\n\nIn conclusion,this plot ranks the predictors by their influence on the model's ability to predict weight.Predictors with higher bars are more critical for the model, meaning changes in these predictors are associated with more significant changes in weight.\n","srcMarkdownNoYaml":"\n\n**Research Question 2:**\n\nHow do factors like high-caloric food intake, smoking habits, vegetable intake and technology dependency correlate with weight?\n\n**Methodology:**\n\nThe above research question can be solved by using multilinear regression and variable selection.Adjusted R-square values is used as a criterion to perform the variable selection.\n\n**The statistical analysis of this dataset involves several steps:**\n\n-   **Data Loading:**\n\nFirstly,we need to load the CSV file.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\nlibrary(ggplot2)\nlibrary(car)\nlibrary(caret)\nlibrary(MASS)\nlibrary(dplyr)\n\ndata <- read.csv(\"C:\\\\Users\\\\arava\\\\OneDrive\\\\Desktop\\\\STAT515\\\\modified_obesity_data.csv\")\n```\n\n-   **Data Preprocessing:**\n\nThis step involves data cleaning where rows with missing values are deleted and categorical variables are converted into dummy numerical variables.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\n\ndata <- na.omit(data)\ndata$Highcaloric_food <- as.numeric(data$Highcaloric_food == \"yes\")\ndata$Smoking_Habit <- as.numeric(data$Smoking_Habit == \"yes\")\n```\n\n-   **Model Building:**\n\nWe build a linear model with Highcaloric_food, Smoking_Habit, Vegetable_intake and Technology_dependency as predictors and Weight as the dependent variable.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\nlm_model <- lm(Weight ~ Highcaloric_food + Vegetable_intake + Smoking_Habit + Technology_dependency, data = data)\n\n```\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\nstepwise_adj_r2 <- function(model, data) {\n  current_adj_r2 <- summary(model)$adj.r.squared\n  predictors <- names(coef(model))\n  best_model <- model\n  improvement <- TRUE\n  \n  while (improvement) {\n    improvement <- FALSE\n    best_adj_r2 <- current_adj_r2\n    \n    for (predictor in predictors[-1]) { \n      formula <- as.formula(paste(\"Weight ~\", paste(setdiff(predictors[-1], predictor), collapse = \" + \")))\n      candidate_model <- lm(formula, data = data)\n      candidate_adj_r2 <- summary(candidate_model)$adj.r.squared\n      \n      if (candidate_adj_r2 > best_adj_r2) {\n        best_adj_r2 <- candidate_adj_r2\n        best_model <- candidate_model\n        improvement <- TRUE\n      }\n    }\n    \n    if (improvement) {\n      current_adj_r2 <- best_adj_r2\n      predictors <- names(coef(best_model))\n    }\n  }\n  \n  return(best_model)\n}\n```\n\n-   **Variable Selection:**\n\nAfter building  a model the next step is to perform Stepwise regression which is a variable selection technique by taking Adjusted R-squared values as a criterion to improve the model fitting.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\nfinal_model <- stepwise_adj_r2(lm_model, data)\n```\n\n-   **Displaying the Outputs and Plots:**\n\n After performing stepwise selection the summary of the final model is printed which gives the coefficients, significance levels, and statistics like R-squared values and F-statistics.We also print the coefficient plot, residual plot and variable Importance plot.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\nsummary_final_model <- summary(final_model)\nprint(summary_final_model)\n```\n\n**Summary of the model:**\n\n-   **Residuals:**\n\nResiduals are the differences between the observed values of the dependent variable (Weight) and the values predicted by the model.\n\n**Min**\n\nThe model underpredicted this observation by 55.505 units, given the smallest residual as -55.505.\n\n**First Quartile**\n\nFor a quarter of the data, the model's predictions are around 17.647 units too high, as indicated by 25% of the residuals being smaller than -17.647.\n\n**Median**\n\nThe median residual is very close to 0 (0.165), indicating that the model's predictions are generally accurate, as half of the residuals are below this value and half are above.\n\n**Third Quartile**\n\nMost observations have the model's prediction within about 15.725 units of the actual values, as indicated by the 75% of residuals being smaller than 15.725**.**\n\n**Max**\n\nThe greatest residual, which is 78.498 units, indicates that the highest underprediction of the model for any given observation is 78.498 units.\n\n-   **Coefficients:**\n\nThe predictors' coefficients indicate the expected rise in the dependent variable (weight) for each unit increase in the predictor, assuming no change in the other predictors.\n\n**Intercept**\n\nThe expected weight is about 42.33 units when all predictors are zero.\n\n**Highcaloric_food**\n\nIn comparison to not consuming high-calorie food, there is an average weight rise of 23.19 units linked to high-calorie food consumption\n\n**Vegetable_intake**\n\nWeight increases by around 10.66 units for every unit increase in vegetable intake.\n\n**Smoking_Habit**\n\nThe average weight rise of smokers  is 8.35 units higher than that of non-smokers.\n\n**Technology_dependency**\n\nWeight drops by 3.00 units for every unit increase in technological dependency.\n\n-   **Statistical Significance(Pr(\\>\\|t\\|)):**\n\n    It provides the p values to determine whether the model is statistically significant or not.Significance level(alpha) is generally set to 0.05. The null hypothesis states that no effect or no difference between groups whereas the alternative hypothesis stating that there is a  difference between groups.If the p\\< alpha(0.05)  the model is considered statistically significant, and the null hypothesis is rejected in favor of the alternative hypothesis.From the summary we can see that p values of all the predictors \\< 0.05 therefore suggesting that the model is statistically significant.\n\n-   **Residual Standard Error:**\n\n    This indicates how much the expected values differ from the actual values on an average.The deviation of the model is around 24.54 weight units.\n\n-   **Multiple R-squared (0.1283) and Adjusted R-squared (0.1266):**\n\n    The model accounts for approximately 12.83% of the variance observed in the dependent variable, weight.When several predictors are present, the adjusted measure becomes more accurate since it accounts for approximately 12.66% of the variation in the model.\n\n-   **F-statistic and its p-value:**\n\n```         \nThis tests whether at least one predictor variable has a non-zero coefficient or not. The less p values states that the model is statistically significant.\n```\n\nIn conclusion we can say that the model is statistically significant but with an Adjusted R-squared value of 0.1266 we can say that there is a small variance in the weight.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\n# Coefficient plot\ncoef_plot_adj_r2 <- ggplot(data = as.data.frame(coef(summary(final_model))), aes(x = rownames(coef(summary(final_model))), y = Estimate)) +\n  geom_bar(stat = \"identity\", fill = \"orange\", color = \"black\") +\n  labs(title = \"Coefficients of Predictors (Adjusted R-Squared Criterion)\", x = \"Predictors\", y = \"Coefficient Estimate\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\nprint(coef_plot_adj_r2)\n```\n\nThe above bar chart displays the coefficient estimates for each predictor in the regression model.\n\n**Implications of the Coefficients:**\n\n**Positive coefficients**(Highcaloric_food, Vegetable_intake, Smoking_Habit) shows a direct relationship with weight, where increases in these variables are associated with increases in weight.\n\n**Negative coefficient** (Technology_dependency) shows an inverse relationship, where increases in this variable are associated with decreases in weight.\n\n**Conclusion:**\n\nThe strength and influence of each predictor on the dependent variable weight, are shown by the relative sizes of the bars. Highcaloric_food shows the most dominant effect, followed by vegetable_intake suggesting that these variables are the most important contributors to the difference in weight shown in your data. The figure clearly illustrates the various effects of dietary and lifestyle choices on weight and offers a visual representation of the regression results that were previously presented.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\n# Residual plot\nresidual_plot_adj_r2 <- ggplot(data, aes(x = fitted(final_model), y = residuals(final_model))) +\n  geom_point(color = \"black\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Residual Plot (Adjusted R-Squared Criterion)\", x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()\nprint(residual_plot_adj_r2)\n```\n\nThe residual shows the residuals on the vertical axis (the differences between observed and predicted values) plotted against the fitted values(predicted) on the horizontal axis.The dashed red line at zero indicates perfect prediction by the model.The residual plot shows residuals scattered randomly around zero, mostly on the positive side. However, distinct clusters around certain predictions, such as 80 and 100, suggest possible missing nonlinear effects or interactions in the model.Extreme outliers, both above and below the zero line, require investigation for potential data errors.Clear patterns, such as vertical clustering, indicate potential issues like incorrect assumptions about variable relationships or overrepresentation of predictor levels in certain ranges.\n\nIn conclusion,the residual plot is a tool for diagnostic checking. It helps in assessing whether the assumptions of linear regression (linearity, independence, constant varience, and normality of residuals) are reasonably satisfied or if further model improvements are needed or not.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\n# Variable importance plot\nvar_importance_adj_r2 <- ggplot(data = as.data.frame(varImp(final_model)), aes(x = rownames(varImp(final_model)), y = Overall)) +\n  geom_bar(stat = \"identity\", fill = \"cornsilk\", color = \"black\") +\n  labs(title = \"Variable Importance\", x = \"Predictors\", y = \"Importance\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\nprint(var_importance_adj_r2)\n```\n\nThe Variable Importance bar chart visually represents the relative importance of different predictors in the regression model. Highcaloric_food predictor has the highest importance in the model, indicating that it has a potential effect on the dependent variable (weight). This aligns with the earlier regression output where the coefficient for high-caloric food intake was significantly positive, suggesting a strong association with increased weight. Smoking_habit shows the least importance compared to all the predictors. This lesser importance reflects its relatively lower coefficient and it was also marginally significant in the regression analysis (p-value close to the typical significance threshold of 0.05).\n\nIn conclusion,this plot ranks the predictors by their influence on the model's ability to predict weight.Predictors with higher bars are more critical for the model, meaning changes in these predictors are associated with more significant changes in weight.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"Research Question 2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","editor":"visual","theme":"pulse","title":"Research Question 2"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}